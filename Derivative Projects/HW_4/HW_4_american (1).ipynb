{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYnesQileDvB"
      },
      "outputs": [],
      "source": [
        "# Enhanced FX Barrier Option Pricer for American Up-and-Out Options\n",
        "import time\n",
        "from typing import Any, Callable, Dict, List, Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class OptimizedAmericanBarrierPricer:\n",
        "    \"\"\"\n",
        "    Optimized Monte Carlo pricer for American up-and-out FX barrier options\n",
        "    Focus on accuracy to the fourth decimal place\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_paths: int = 500000,  # Increased for fourth decimal accuracy\n",
        "        num_steps: int = 252,\n",
        "        seed: int = 42,\n",
        "        antithetic: bool = True,\n",
        "        control_variate: bool = True,\n",
        "    ):\n",
        "        self.num_paths = num_paths\n",
        "        self.num_steps = num_steps\n",
        "        self.seed = seed\n",
        "        self.antithetic = antithetic\n",
        "        self.control_variate = control_variate\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    def generate_paths(\n",
        "        self,\n",
        "        S0_K: float,\n",
        "        T: float,\n",
        "        r: float,\n",
        "        sigma: float,\n",
        "        sigma_curve: Callable[[np.ndarray], np.ndarray] = None,\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"Generate optimized price paths with higher precision\"\"\"\n",
        "        dt = T / self.num_steps\n",
        "        effective_paths = self.num_paths // 2 if self.antithetic else self.num_paths\n",
        "\n",
        "        # Use higher precision random numbers\n",
        "        Z = np.random.normal(0, 1, size=(effective_paths, self.num_steps)).astype(np.float64)\n",
        "\n",
        "        if self.antithetic:\n",
        "            paths = np.zeros((self.num_paths, self.num_steps + 1), dtype=np.float64)\n",
        "        else:\n",
        "            paths = np.zeros((effective_paths, self.num_steps + 1), dtype=np.float64)\n",
        "\n",
        "        paths[:, 0] = S0_K\n",
        "        time_grid = np.linspace(0, T, self.num_steps + 1)\n",
        "\n",
        "        for t in range(1, self.num_steps + 1):\n",
        "            if sigma_curve is not None:\n",
        "                vol = sigma_curve(time_grid[t])\n",
        "            else:\n",
        "                vol = sigma\n",
        "\n",
        "            drift = (r - 0.5 * vol**2) * dt\n",
        "            diffusion = vol * np.sqrt(dt)\n",
        "\n",
        "            if self.antithetic:\n",
        "                increment_1 = drift + diffusion * Z[:, t - 1]\n",
        "                increment_2 = drift - diffusion * Z[:, t - 1]\n",
        "\n",
        "                paths[:effective_paths, t] = paths[:effective_paths, t - 1] * np.exp(increment_1)\n",
        "                paths[effective_paths:, t] = paths[effective_paths:, t - 1] * np.exp(increment_2)\n",
        "            else:\n",
        "                paths[:, t] = paths[:, t - 1] * np.exp(drift + diffusion * Z[:, t - 1])\n",
        "\n",
        "        return paths\n",
        "\n",
        "    def longstaff_schwartz_barrier(\n",
        "        self,\n",
        "        paths: np.ndarray,\n",
        "        B_K: float,\n",
        "        r: float,\n",
        "        T: float,\n",
        "        option_type: str = \"call\",\n",
        "        basis_funcs: List[Callable[[np.ndarray], np.ndarray]] = None,\n",
        "    ) -> Tuple[float, float]:\n",
        "        \"\"\"\n",
        "        Enhanced Longstaff-Schwartz for American up-and-out barrier options\n",
        "        Returns price and standard error\n",
        "        \"\"\"\n",
        "        num_paths, num_steps_plus_one = paths.shape\n",
        "        num_steps = num_steps_plus_one - 1\n",
        "        dt = T / num_steps\n",
        "\n",
        "        if basis_funcs is None:\n",
        "            # Enhanced basis functions for better accuracy\n",
        "            basis_funcs = [\n",
        "                lambda x: np.ones_like(x),\n",
        "                lambda x: x,\n",
        "                lambda x: x**2,\n",
        "                lambda x: x**3,\n",
        "                lambda x: np.maximum(x - 1.0, 0),  # Intrinsic value\n",
        "                lambda x: np.log(x) if np.all(x > 0) else np.zeros_like(x),\n",
        "            ]\n",
        "\n",
        "        # Track barrier hits\n",
        "        barrier_hit = np.any(paths >= B_K, axis=1)\n",
        "\n",
        "        # Initialize cash flows\n",
        "        cash_flows = np.zeros((num_paths, num_steps_plus_one))\n",
        "\n",
        "        # Final payoff (only if barrier not hit)\n",
        "        if option_type == \"call\":\n",
        "            final_payoff = np.maximum(paths[:, -1] - 1.0, 0)\n",
        "        else:\n",
        "            final_payoff = np.maximum(1.0 - paths[:, -1], 0)\n",
        "\n",
        "        cash_flows[:, -1] = np.where(barrier_hit, 0, final_payoff)\n",
        "\n",
        "        # Backward induction\n",
        "        for t in range(num_steps - 1, 0, -1):\n",
        "            # Check if barrier hit up to this point\n",
        "            barrier_hit_so_far = np.any(paths[:, :t+1] >= B_K, axis=1)\n",
        "\n",
        "            # Exercise value (zero if barrier hit)\n",
        "            if option_type == \"call\":\n",
        "                exercise_value = np.maximum(paths[:, t] - 1.0, 0)\n",
        "            else:\n",
        "                exercise_value = np.maximum(1.0 - paths[:, t], 0)\n",
        "\n",
        "            exercise_value = np.where(barrier_hit_so_far, 0, exercise_value)\n",
        "\n",
        "            # Only consider paths that are in-the-money and haven't hit barrier\n",
        "            itm_and_alive = (exercise_value > 0) & (~barrier_hit_so_far)\n",
        "            itm_indices = np.where(itm_and_alive)[0]\n",
        "\n",
        "            if len(itm_indices) > 10:  # Need sufficient data points\n",
        "                try:\n",
        "                    X = np.column_stack([\n",
        "                        f(paths[itm_indices, t]) for f in basis_funcs\n",
        "                        if not (hasattr(f, '__name__') and f.__name__ == '<lambda>' and 'log' in str(f))\n",
        "                        or np.all(paths[itm_indices, t] > 0)\n",
        "                    ])\n",
        "\n",
        "                    # Continuation value\n",
        "                    Y = np.exp(-r * dt) * cash_flows[itm_indices, t + 1]\n",
        "\n",
        "                    # Regularized regression for stability\n",
        "                    beta, residuals, rank, s = np.linalg.lstsq(X, Y, rcond=1e-10)\n",
        "                    continuation_value = np.dot(X, beta)\n",
        "\n",
        "                    # Exercise decision\n",
        "                    for i, path_idx in enumerate(itm_indices):\n",
        "                        if exercise_value[path_idx] > continuation_value[i]:\n",
        "                            cash_flows[path_idx, t] = exercise_value[path_idx]\n",
        "                            cash_flows[path_idx, t + 1:] = 0\n",
        "                        else:\n",
        "                            cash_flows[path_idx, t] = 0\n",
        "\n",
        "                except np.linalg.LinAlgError:\n",
        "                    # Fallback to simple continuation\n",
        "                    for path_idx in itm_indices:\n",
        "                        cash_flows[path_idx, t] = 0\n",
        "\n",
        "        # Calculate price\n",
        "        discount_factors = np.exp(-r * np.arange(num_steps_plus_one) * dt)\n",
        "        discounted_cash_flows = cash_flows * discount_factors[np.newaxis, :]\n",
        "        option_values = np.sum(discounted_cash_flows, axis=1)\n",
        "\n",
        "        price = np.mean(option_values)\n",
        "        std_error = np.std(option_values) / np.sqrt(num_paths)\n",
        "\n",
        "        return price, std_error\n",
        "\n",
        "    def sample_parameter_space_optimized(\n",
        "        self,\n",
        "        bounds: Dict[str, Tuple[float, float]],\n",
        "        num_samples: int = 1000,\n",
        "        method: str = \"sobol\",\n",
        "    ) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Optimized parameter space sampling with better coverage\"\"\"\n",
        "        np.random.seed(self.seed)\n",
        "        samples = {}\n",
        "\n",
        "        if method == \"sobol\":\n",
        "            try:\n",
        "                from scipy.stats.qmc import Sobol\n",
        "                param_names = list(bounds.keys())\n",
        "                n_dims = len(param_names)\n",
        "\n",
        "                # Ensure number of samples is power of 2 for Sobol\n",
        "                sobol_samples_count = 2 ** int(np.ceil(np.log2(num_samples)))\n",
        "                sampler = Sobol(d=n_dims, scramble=True, seed=self.seed)\n",
        "                sobol_samples = sampler.random(n=sobol_samples_count)\n",
        "\n",
        "                # Take only the requested number of samples\n",
        "                sobol_samples = sobol_samples[:num_samples]\n",
        "\n",
        "                for i, param in enumerate(param_names):\n",
        "                    lower, upper = bounds[param]\n",
        "                    samples[param] = lower + (upper - lower) * sobol_samples[:, i]\n",
        "\n",
        "            except ImportError:\n",
        "                print(\"Scipy not available, using Latin Hypercube\")\n",
        "                method = \"latin_hypercube\"\n",
        "\n",
        "        if method == \"latin_hypercube\":\n",
        "            try:\n",
        "                from scipy.stats.qmc import LatinHypercube\n",
        "                param_names = list(bounds.keys())\n",
        "                n_dims = len(param_names)\n",
        "\n",
        "                sampler = LatinHypercube(d=n_dims, seed=self.seed)\n",
        "                lhs_samples = sampler.random(n=num_samples)\n",
        "\n",
        "                for i, param in enumerate(param_names):\n",
        "                    lower, upper = bounds[param]\n",
        "                    samples[param] = lower + (upper - lower) * lhs_samples[:, i]\n",
        "\n",
        "            except ImportError:\n",
        "                print(\"Falling back to stratified uniform sampling\")\n",
        "                for param, (lower, upper) in bounds.items():\n",
        "                    # Stratified sampling for better coverage\n",
        "                    strata = int(np.sqrt(num_samples))\n",
        "                    samples_per_stratum = num_samples // strata\n",
        "                    param_samples = []\n",
        "\n",
        "                    for i in range(strata):\n",
        "                        stratum_lower = lower + i * (upper - lower) / strata\n",
        "                        stratum_upper = lower + (i + 1) * (upper - lower) / strata\n",
        "                        stratum_samples = np.random.uniform(\n",
        "                            stratum_lower, stratum_upper, samples_per_stratum\n",
        "                        )\n",
        "                        param_samples.extend(stratum_samples)\n",
        "\n",
        "                    # Fill remaining samples\n",
        "                    remaining = num_samples - len(param_samples)\n",
        "                    if remaining > 0:\n",
        "                        param_samples.extend(\n",
        "                            np.random.uniform(lower, upper, remaining)\n",
        "                        )\n",
        "\n",
        "                    samples[param] = np.array(param_samples[:num_samples])\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def run_american_barrier_pricing(\n",
        "        self,\n",
        "        samples: Dict[str, np.ndarray],\n",
        "        option_type: str = \"call\",\n",
        "        use_tqdm: bool = True,\n",
        "        save_results: bool = True,\n",
        "        filename_prefix: str = \"american_up_out\",\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Run American up-and-out barrier option pricing with high accuracy\n",
        "        \"\"\"\n",
        "        num_samples = len(next(iter(samples.values())))\n",
        "        prices = np.zeros(num_samples)\n",
        "        errors = np.zeros(num_samples)\n",
        "\n",
        "        start_time = time.time()\n",
        "        iterator = tqdm(range(num_samples), desc=\"Pricing options\") if use_tqdm else range(num_samples)\n",
        "\n",
        "        for i in iterator:\n",
        "            S0_K = samples[\"S0_K\"][i]\n",
        "            B_K = samples[\"B_K\"][i]\n",
        "            T = samples[\"T\"][i]\n",
        "            r = samples[\"r\"][i]\n",
        "            sigma = samples[\"sigma\"][i]\n",
        "\n",
        "            # Generate paths\n",
        "            paths = self.generate_paths(S0_K, T, r, sigma)\n",
        "\n",
        "            # Price American barrier option\n",
        "            price, std_err = self.longstaff_schwartz_barrier(\n",
        "                paths, B_K, r, T, option_type\n",
        "            )\n",
        "\n",
        "            prices[i] = price\n",
        "            errors[i] = std_err\n",
        "\n",
        "            if not use_tqdm and (i + 1) % 100 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                avg_time_per_sample = elapsed / (i + 1)\n",
        "                remaining_time = avg_time_per_sample * (num_samples - i - 1)\n",
        "                print(f\"Completed {i + 1}/{num_samples}. Est. remaining: {remaining_time:.1f}s\")\n",
        "\n",
        "        # Create results dataframe\n",
        "        results_data = {**samples, \"price\": prices, \"std_error\": errors}\n",
        "        results_df = pd.DataFrame(results_data)\n",
        "\n",
        "        # Add derived metrics\n",
        "        results_df['relative_error'] = results_df['std_error'] / results_df['price']\n",
        "        results_df['confidence_95'] = 1.96 * results_df['std_error']\n",
        "        results_df['moneyness'] = results_df['S0_K']\n",
        "        results_df['barrier_distance'] = results_df['B_K'] - results_df['S0_K']\n",
        "\n",
        "        if save_results:\n",
        "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"{filename_prefix}_{option_type}_{timestamp}.csv\"\n",
        "            results_df.to_csv(filename, index=False)\n",
        "            print(f\"Results saved to {filename}\")\n",
        "\n",
        "        return {\n",
        "            \"samples\": samples,\n",
        "            \"prices\": prices,\n",
        "            \"errors\": errors,\n",
        "            \"option_type\": option_type,\n",
        "            \"dataframe\": results_df,\n",
        "            \"summary_stats\": self._calculate_summary_stats(results_df),\n",
        "        }\n",
        "\n",
        "    def _calculate_summary_stats(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate summary statistics for the pricing results\"\"\"\n",
        "        return {\n",
        "            \"price_stats\": {\n",
        "                \"mean\": df['price'].mean(),\n",
        "                \"std\": df['price'].std(),\n",
        "                \"min\": df['price'].min(),\n",
        "                \"max\": df['price'].max(),\n",
        "                \"median\": df['price'].median(),\n",
        "            },\n",
        "            \"error_stats\": {\n",
        "                \"mean_std_error\": df['std_error'].mean(),\n",
        "                \"max_std_error\": df['std_error'].max(),\n",
        "                \"mean_relative_error\": df['relative_error'].mean(),\n",
        "                \"max_relative_error\": df['relative_error'].max(),\n",
        "            },\n",
        "            \"parameter_correlations\": df[['S0_K', 'B_K', 'T', 'r', 'sigma', 'price']].corr()['price'].to_dict(),\n",
        "        }\n",
        "\n",
        "    def create_comprehensive_plots(self, results: Dict):\n",
        "        \"\"\"Create comprehensive visualization of results\"\"\"\n",
        "        df = results[\"dataframe\"]\n",
        "        option_type = results[\"option_type\"]\n",
        "\n",
        "        # Create subplots\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=3,\n",
        "            subplot_titles=[\n",
        "                f\"Price vs Spot/Strike ({option_type.title()})\",\n",
        "                f\"Price vs Barrier/Strike ({option_type.title()})\",\n",
        "                f\"Price vs Time to Maturity ({option_type.title()})\",\n",
        "                f\"Price vs Volatility ({option_type.title()})\",\n",
        "                f\"Price vs Interest Rate ({option_type.title()})\",\n",
        "                \"Pricing Errors Distribution\"\n",
        "            ],\n",
        "            specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"scatter\"}],\n",
        "                   [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"histogram\"}]]\n",
        "        )\n",
        "\n",
        "        # Plot 1: Price vs S0/K\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=df['S0_K'], y=df['price'], mode='markers',\n",
        "                marker=dict(color=df['T'], colorscale='Viridis', size=4),\n",
        "                name='Price vs S0/K', showlegend=False\n",
        "            ), row=1, col=1\n",
        "        )\n",
        "\n",
        "        # Plot 2: Price vs B/K\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=df['B_K'], y=df['price'], mode='markers',\n",
        "                marker=dict(color=df['sigma'], colorscale='Plasma', size=4),\n",
        "                name='Price vs B/K', showlegend=False\n",
        "            ), row=1, col=2\n",
        "        )\n",
        "\n",
        "        # Plot 3: Price vs T\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=df['T'], y=df['price'], mode='markers',\n",
        "                marker=dict(color=df['r'], colorscale='Cividis', size=4),\n",
        "                name='Price vs T', showlegend=False\n",
        "            ), row=1, col=3\n",
        "        )\n",
        "\n",
        "        # Plot 4: Price vs Volatility\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=df['sigma'], y=df['price'], mode='markers',\n",
        "                marker=dict(color=df['S0_K'], colorscale='Turbo', size=4),\n",
        "                name='Price vs Sigma', showlegend=False\n",
        "            ), row=2, col=1\n",
        "        )\n",
        "\n",
        "        # Plot 5: Price vs Interest Rate\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=df['r'], y=df['price'], mode='markers',\n",
        "                marker=dict(color=df['B_K'], colorscale='Spectral', size=4),\n",
        "                name='Price vs r', showlegend=False\n",
        "            ), row=2, col=2\n",
        "        )\n",
        "\n",
        "        # Plot 6: Error distribution\n",
        "        fig.add_trace(\n",
        "            go.Histogram(\n",
        "                x=df['relative_error'], nbinsx=50,\n",
        "                name='Relative Error Dist', showlegend=False\n",
        "            ), row=2, col=3\n",
        "        )\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f\"American Up-and-Out {option_type.title()} Option Analysis\",\n",
        "            height=800,\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        fig.show()\n",
        "\n",
        "        # Create 3D surface plot\n",
        "        self._create_3d_surface_plot(df, option_type)\n",
        "\n",
        "    def _create_3d_surface_plot(self, df: pd.DataFrame, option_type: str):\n",
        "        \"\"\"Create 3D surface plot for key parameters\"\"\"\n",
        "        fig = go.Figure()\n",
        "\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=df['S0_K'],\n",
        "            y=df['B_K'],\n",
        "            z=df['price'],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                size=3,\n",
        "                color=df['price'],\n",
        "                colorscale='Viridis',\n",
        "                showscale=True,\n",
        "                colorbar=dict(title=\"Option Price\")\n",
        "            ),\n",
        "            text=[f\"T={t:.2f}, Ïƒ={s:.2f}, r={r:.3f}\" for t, s, r in zip(df['T'], df['sigma'], df['r'])],\n",
        "            hovertemplate=\"S0/K: %{x:.3f}<br>B/K: %{y:.3f}<br>Price: %{z:.4f}<br>%{text}<extra></extra>\"\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f\"American Up-and-Out {option_type.title()} Option Price Surface\",\n",
        "            scene=dict(\n",
        "                xaxis_title=\"S0/K (Spot/Strike)\",\n",
        "                yaxis_title=\"B/K (Barrier/Strike)\",\n",
        "                zaxis_title=\"Option Price\",\n",
        "                camera=dict(eye=dict(x=1.2, y=1.2, z=1.2))\n",
        "            ),\n",
        "            width=900,\n",
        "            height=700\n",
        "        )\n",
        "\n",
        "        fig.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    print(\"=== American Up-and-Out FX Barrier Option Pricer ===\\n\")\n",
        "\n",
        "    # Initialize pricer with high precision settings\n",
        "    pricer = OptimizedAmericanBarrierPricer(\n",
        "        num_paths=500000,  # High path count for fourth decimal accuracy\n",
        "        num_steps=252,\n",
        "        antithetic=True,\n",
        "        control_variate=True\n",
        "    )\n",
        "\n",
        "    # Define parameter bounds for American up-and-out options\n",
        "    # These ranges are chosen to capture economically meaningful scenarios\n",
        "\n",
        "    call_bounds = {\n",
        "        \"S0_K\": (0.85, 1.15),    # Spot around strike (out-of-money to in-the-money)\n",
        "        \"B_K\": (1.05, 1.50),    # Barrier above strike (typical for up-and-out)\n",
        "        \"T\": (0.08, 2.0),       # 1 month to 2 years\n",
        "        \"r\": (0.0, 0.08),       # 0% to 8% interest rates\n",
        "        \"sigma\": (0.08, 0.50),  # 8% to 50% volatility (FX typical range)\n",
        "    }\n",
        "\n",
        "    put_bounds = {\n",
        "        \"S0_K\": (0.85, 1.15),    # Same range for puts\n",
        "        \"B_K\": (1.05, 1.50),    # Barrier above current spot\n",
        "        \"T\": (0.08, 2.0),\n",
        "        \"r\": (0.0, 0.08),\n",
        "        \"sigma\": (0.08, 0.50),\n",
        "    }\n",
        "\n",
        "    # Number of samples for the hypercube\n",
        "    num_samples = 5000  # Adjust based on computational resources\n",
        "\n",
        "    print(\"Generating parameter samples using Sobol sequence...\")\n",
        "\n",
        "    # Generate samples for calls\n",
        "    call_samples = pricer.sample_parameter_space_optimized(\n",
        "        call_bounds, num_samples=num_samples, method=\"sobol\"\n",
        "    )\n",
        "\n",
        "    # Generate samples for puts\n",
        "    put_samples = pricer.sample_parameter_space_optimized(\n",
        "        put_bounds, num_samples=num_samples, method=\"sobol\"\n",
        "    )\n",
        "\n",
        "    print(f\"Generated {num_samples} samples for each option type\\n\")\n",
        "\n",
        "    # Price American up-and-out call options\n",
        "    print(\"Pricing American up-and-out CALL options...\")\n",
        "    call_results = pricer.run_american_barrier_pricing(\n",
        "        call_samples,\n",
        "        option_type=\"call\",\n",
        "        use_tqdm=True,\n",
        "        save_results=True,\n",
        "        filename_prefix=\"american_up_out_call\"\n",
        "    )\n",
        "\n",
        "    # Price American up-and-out put options\n",
        "    print(\"\\nPricing American up-and-out PUT options...\")\n",
        "    put_results = pricer.run_american_barrier_pricing(\n",
        "        put_samples,\n",
        "        option_type=\"put\",\n",
        "        use_tqdm=True,\n",
        "        save_results=True,\n",
        "        filename_prefix=\"american_up_out_put\"\n",
        "    )\n",
        "\n",
        "    # Display results summary\n",
        "    print(\"\\n=== CALL OPTIONS SUMMARY ===\")\n",
        "    call_stats = call_results[\"summary_stats\"]\n",
        "    print(f\"Average Price: {call_stats['price_stats']['mean']:.6f}\")\n",
        "    print(f\"Price Range: [{call_stats['price_stats']['min']:.6f}, {call_stats['price_stats']['max']:.6f}]\")\n",
        "    print(f\"Average Std Error: {call_stats['error_stats']['mean_std_error']:.6f}\")\n",
        "    print(f\"Average Relative Error: {call_stats['error_stats']['mean_relative_error']:.4%}\")\n",
        "\n",
        "    print(\"\\n=== PUT OPTIONS SUMMARY ===\")\n",
        "    put_stats = put_results[\"summary_stats\"]\n",
        "    print(f\"Average Price: {put_stats['price_stats']['mean']:.6f}\")\n",
        "    print(f\"Price Range: [{put_stats['price_stats']['min']:.6f}, {put_stats['price_stats']['max']:.6f}]\")\n",
        "    print(f\"Average Std Error: {put_stats['error_stats']['mean_std_error']:.6f}\")\n",
        "    print(f\"Average Relative Error: {put_stats['error_stats']['mean_relative_error']:.4%}\")\n",
        "\n",
        "    # Create visualizations\n",
        "    print(\"\\nGenerating visualizations...\")\n",
        "    pricer.create_comprehensive_plots(call_results)\n",
        "    pricer.create_comprehensive_plots(put_results)\n",
        "\n",
        "    return call_results, put_results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    call_results, put_results = main()\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras import callbacks\n",
        "from keras.layers import Activation, Add, Dense, Input\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Fix random seeds for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "\n",
        "df_list = [\n",
        "    call_results[\"dataframe\"],\n",
        "    put_results[\"dataframe\"],\n",
        "]\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Drop rows where the price is NaN and remove duplicates\n",
        "df = df.dropna().drop_duplicates()\n",
        "\n",
        "# Prepare features and target\n",
        "X = df.drop(\"price\", axis=1)  # Features\n",
        "y = df[\"price\"]  # Target variable\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "\n",
        "# Define residual block function\n",
        "def residual_block(x, units=100):\n",
        "    shortcut = x\n",
        "    out = Dense(units, activation=\"gelu\")(x)\n",
        "    out = Dense(units)(out)\n",
        "    out = Add()([shortcut, out])\n",
        "    out = Activation(\"gelu\")(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "# Build model with residual blocks\n",
        "inputs = Input(shape=(X_train.shape[1],))\n",
        "x = Dense(100, activation=\"gelu\")(inputs)\n",
        "\n",
        "for _ in range(3):\n",
        "    x = residual_block(x, units=100)\n",
        "\n",
        "outputs = Dense(1, activation=\"gelu\")(x)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adamw\", loss=\"mae\", metrics=[\"mae\"])\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-7, verbose=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train, epochs=100, validation_split=0.2, callbacks=[lr_scheduler]\n",
        ")\n",
        "\n",
        "# Evaluate on the test set\n",
        "model.evaluate(X_test, y_test)\n",
        "model.save(\"trained_modelAM.keras\")\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate absolute percentage errors\n",
        "ape = np.abs((y_test - y_pred.flatten()) / y_test)\n",
        "\n",
        "# Calculate the fraction of test samples with error <= 1%\n",
        "frac_within_1pct = np.mean(ape <= 0.01)\n",
        "\n",
        "print(f\"Fraction of test samples with <= 1% absolute error: {frac_within_1pct:.4f}\")\n",
        "\n",
        "if frac_within_1pct >= 0.99:\n",
        "    print(\"Success: At least 99% of test samples have error <= 1%.\")\n",
        "else:\n",
        "    print(\"Warning: Less than 99% of test samples have error <= 1%.\")"
      ]
    }
  ]
}